{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WBS Project 2 - Eniac - Cleaning and Categories\n",
    "\n",
    "Mathis Lammert\n",
    "\n",
    "mathislammert@gmail.com\n",
    "\n",
    "Created: 2024-03-11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \".\\data\\\\\"\n",
    "\n",
    "brands = pd.DataFrame(pd.read_csv(folder+\"brands.csv\"))\n",
    "items = pd.DataFrame(pd.read_csv(folder+\"orderlines.csv\"))\n",
    "orders = pd.DataFrame(pd.read_csv(folder+\"orders.csv\"))\n",
    "products = pd.DataFrame(pd.read_csv(folder+\"products.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data online\n",
    "# def gd_path(file_id):\n",
    "#     \"\"\"Generate a shareable link from Google Drive file id.\"\"\"\n",
    "#     return f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "\n",
    "# # Google Drive file ids\n",
    "# files_id = {\n",
    "#     \"brands\": \"1m1ThDDIYRTTii-rqM5SEQjJ8McidJskD\",\n",
    "#     \"items\": \"1FYhN_2AzTBFuWcfHaRuKcuCE6CWXsWtG\",\n",
    "#     \"orders\": \"1Vu0q91qZw6lqhIqbjoXYvYAQTmVHh6uZ\",\n",
    "#     \"products\": \"1afxwDXfl-7cQ_qLwyDitfcCx3u7WMvkU\"\n",
    "# }\n",
    "\n",
    "# # Read data from Google Drive\n",
    "# orders = pd.DataFrame(pd.read_csv(gd_path(files_id[\"orders\"])))\n",
    "# items = pd.DataFrame(pd.read_csv(gd_path(files_id[\"items\"])))\n",
    "# products = pd.DataFrame(pd.read_csv(gd_path(files_id[\"products\"])))\n",
    "# brands = pd.DataFrame(pd.read_csv(gd_path(files_id[\"brands\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abnormalities\n",
    "\n",
    "Exploration found several abnormalities:\n",
    "- items.product_id is empty - can be dropped\n",
    "- product_quantity has max 999 - thats not realistic and seems like a placeholder - investigate\n",
    "- dates are not dtype date in orders\n",
    "- items.unit_price is object but should be float - are non-digits in there?\n",
    "- there is on unit_price with \"-119.00\"\n",
    "- products.promo_price \n",
    "- correct prices in product table as well (same problem as in items?)\n",
    "- products.type is an object but supposed to be an numerical code \n",
    "- promo price is way bigger than regular price in some instances\n",
    "- why are promotion prices so big?\n",
    "- how to calculate revenue\n",
    "- possible product categories\n",
    "- some prices are NaA\n",
    "- some order_ids are not there in items..?!?!\n",
    "- the prices actually dont always have 2 decimals - my approach is not valid\n",
    "- price relationships are weird - price, unit_price and promo_price\n",
    "- there are duplicates - must be checked and dropped before\n",
    "- app. there are \n",
    "- maybe drop incomplete cases (shopping basket, etc)? how many cases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  data types \"date\"\n",
    "orders[\"created_date\"] = pd.to_datetime(orders[\"created_date\"])   # as date\n",
    "items[\"date\"] = pd.to_datetime(items[\"date\"]) # as date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop unused column\n",
    "items = items.drop(columns=\"product_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names\n",
    "items.rename(columns={\"id_order\": \"order_id\"}, inplace=True)   # so that orders and items have identical order_id -names\n",
    "orders.rename(columns={\"created_date\":\"date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and Drop duplicates\n",
    "items.duplicated().value_counts() # -> no duplicates in items\n",
    "orders.duplicated().value_counts() # -> no duplicates in orders\n",
    "products.duplicated().value_counts() # -> many duplicates in products -\n",
    "products = products.loc[~products.duplicated()] # -> drop them\n",
    "brands.duplicated().value_counts() # -> no duplicates in brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for and remove missing values\n",
    "products.price.isna().value_counts() # -> only 46 products dont have a price -> delete them!\n",
    "products = products.loc[~products.price.isna()]\n",
    "\n",
    "products.isna().sum() # -> other NAs are in desc - leave it, not important for now \n",
    "items.isna().sum() # -> no NAs here\n",
    "orders.isna().sum() # -> 5 NAs in total_paid - need to delete it\n",
    "del_orderid = orders.loc[orders.total_paid.isna(), \"order_id\"].tolist() # create list of ID that need to be deleted..\n",
    "orders = orders.loc[~orders.order_id.isin(del_orderid)] # .. in orders\n",
    "items = items.loc[~items.order_id.isin(del_orderid)]  #  .. in items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prices - whats the problem?\n",
    "items.loc[items.unit_price.astype(\"str\").str.contains(\"[^0-9.]\")]  # search for substrings that are not digits or points -> there is one value with \"-119.00\"\n",
    "#items.unit_price.astype(\"float\") # -> apper. there is at least on case where the \n",
    "items.loc[items.unit_price.str.len() > 6] # -> this seems to  systematic: thousands and decimals are seperated by point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Regex that finds the faulty price patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexfilter = r'(\\..*?\\..*)|(\\.\\d{3,}$)'\n",
    "products.price.str.contains(regexfilter).value_counts(normalize=True) # this finds these weird patterns (\"10.939.496\") -> they account for 5.1% of the data\n",
    "products.loc[products.price.str.contains(regexfilter)].sample(30)\n",
    "products = products.loc[~products.price.str.contains(regexfilter)] # until a better solution is found - delete them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a function to correct the price, based on this regex pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_cleaner(col):\n",
    "    # Use regex to replace points that are followed by three digits and then by another point or end of the string\n",
    "    col = col.str.replace(r'\\.(\\d{3})(?=\\.|$)', r'\\1', regex=True)\n",
    "\n",
    "    # Convert to float\n",
    "    col = col.astype(float)\n",
    "    return col\n",
    "\n",
    "items[\"unit_price\"] = price_cleaner(items[\"unit_price\"])\n",
    "products[\"price\"] = price_cleaner(products[\"price\"])\n",
    "#products[\"promo_price\"] = price_cleaner(products[\"promo_price\"])\n",
    "products.sort_values(\"price\", ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some price have negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find and delete orders having negative prices in Items or order \n",
    "items.loc[items.unit_price.astype(\"str\").str.contains(\"[^0-9.]\")]  # -> order id 365886\n",
    "items.loc[items.order_id == 365886] \n",
    "orders.loc[orders.order_id == 365886]\n",
    "order = orders.loc[orders.order_id != 365886]\n",
    "items = items.loc[items.order_id != 365886] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repair Promo_price\n",
    "\n",
    "those patterns are even more corrupted. it seems that the decimals are at the wrong place.\n",
    "\n",
    "Approach: Use the first digits. Extract the number of digits from \"unit_price\" which should have the same dimension. \n",
    "\n",
    "Problem: If the promo_price has one dimension less (e.g., unit price 1099€ nad promo_price 999€) this does not work \n",
    "Solution: Multiply by ten in those cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dots from 'promo_price' and ensure it's treated as a string for manipulation\n",
    "products['cleaned_promo_price'] = products.promo_price.str.replace(\".\", \"\", regex=False)\n",
    "\n",
    "# Calculate the length of the integer part of 'price'\n",
    "products[\"price_digits\"] = products.price.round(2).astype(str).str.split(\".\").str[0].str.len()\n",
    "\n",
    "# Extract the first n digits from 'cleaned_promo_price', where n is determined by 'price_digits'\n",
    "# And then insert a decimal point to match the 'price' format\n",
    "def adjust_promo(row):\n",
    "    n = row['price_digits']\n",
    "    # Extract first n digits\n",
    "    first_n_digits = row['cleaned_promo_price'][:n]\n",
    "    last_n_digits = row['cleaned_promo_price'][n+1:n+3]\n",
    "    # Insert decimal point before the last two digits\n",
    "    adjusted_promo_price = first_n_digits + '.' + last_n_digits\n",
    "    adjusted_promo_price = pd.Series(adjusted_promo_price).astype(\"float\")\n",
    "    return adjusted_promo_price\n",
    "\n",
    "products['promo_price_est'] = products.apply(adjust_promo, axis=1)\n",
    "products.drop(columns=['cleaned_promo_price', 'price_digits'], inplace=True) # Drop temporary columns\n",
    "\n",
    "# some weird cases left?\n",
    "(products['promo_price_est'] > products[\"price\"]).value_counts()\n",
    "products.loc[(products['promo_price_est'] > products[\"price\"])] # it seems that in those cases (958), the above approach failed because the promo was one digit cheaper  \n",
    "products.loc[(products['promo_price_est'] > products[\"price\"]), \"promo_price_est\"] = (products['promo_price_est']/10).round(2) #try to just divide it by ten in those cases\n",
    "\n",
    "# drop original promo\n",
    "products.drop(columns=['promo_price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute discount from this adjusted \n",
    "products[\"discount_est\"] = 100-(products[\"promo_price_est\"] * 100 / products[\"price\"]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "product quantity is weirdly high in some cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.sort_values(\"product_quantity\", ascending=False).head(30)\n",
    "orders[orders.order_id == 358747]   # -> app. those high numbers add up but were not actually paid but only in the shopping cart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency tests\n",
    "some order_ids are not in items and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.loc[~orders.order_id.isin(items.order_id)] # there are 22213 entries in orders, that have no corresponding order_id in items.\n",
    "orders = orders.loc[orders.order_id.isin(items.order_id)] # delete them\n",
    "\n",
    "items.loc[~items.order_id.isin(orders.order_id)] # there are 234 entries in items, that have no corresponding order_id in orders\n",
    "items = items.loc[items.order_id.isin(orders.order_id)] # delete them\n",
    "\n",
    "orders.order_id.drop_duplicates().count() == items.order_id.drop_duplicates().count()  # nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKU \n",
    "# are there duplicates?\n",
    "products.sku.duplicated().value_counts() # no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for minor cases in sku\n",
    "products.loc[products.sku.str.contains(\"[a-z]+\")] # check if there are minor cases in products.sku\n",
    "items.loc[items.sku.str.contains(\"[a-z]+\")] # or items.sku - seems to be only one relevant case (par0072)\n",
    "brands.loc[brands.short == \"PAR\"] # for the brands relation it must be mayor case\n",
    "items.loc[items.sku == \"par0072\", \"sku\"] = \"PAR0072\" # change it in both tables\n",
    "products.loc[products.sku == \"par0072\", \"sku\"] = \"PAR0072\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKU length problems\n",
    "products.sku.str.len().value_counts() # oh no, there are SKUs, that have >7 characters (1289 cases)\n",
    "products.loc[products.sku.str.len() > 7].sort_values(\"sku\") #seems like the ast characters are too much\n",
    "products[\"sku_new\"] = products.sku.str[:7] # remove the characters behind the 7th\n",
    "products.sku_new.duplicated().sum() # oh no, we produced duplicates (853), but only in the sku column, the others colum seem to be unique\n",
    "products.loc[products.sku_new.duplicated(keep=False)].sort_values(\"sku_new\").head(30) \n",
    "# those are really different products. the ones with the longer sku have a text starting with \"open\" or \"(open)\" <- what does that mean?\n",
    "# I guess its saver to remove those duplicates, as they originally have another key.\n",
    "items.sku.str.len().value_counts() # yet, those same sku's appear in items. so probably just leave the sku be, even if its to long\n",
    "products.drop(columns=['sku_new'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there SKUs in items, that are not listed in products?\n",
    "(items.sku.isin(products.sku)).value_counts(normalize=True) #yes, 8742 = 2.98%\n",
    "items[~items.sku.isin(products.sku)] # is SKU syntax strange? not really.. so drop it\n",
    "SKU_non_corresponding_ids = items.loc[~items.sku.isin(products.sku), \"order_id\"]  # list of all order_ids where SKU does not correspond\n",
    "orders = orders.loc[~orders.order_id.isin(SKU_non_corresponding_ids)] # remove those IDs in orders\n",
    "items = items.loc[~items.order_id.isin(SKU_non_corresponding_ids)] # ..and in items, as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove non-completed cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.value_counts(\"state\", normalize=True) # complete cases account for 22.7% (46560 orders) - but after the cleaning we did already\n",
    "ids_complete_cases = orders.loc[orders.state == \"Completed\", \"order_id\"]\n",
    "orders = orders.loc[orders.order_id.isin(ids_complete_cases)] # only keep orders having those IDs \n",
    "items = items.loc[items.order_id.isin(ids_complete_cases)] # ..and items as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add unit_prices in items. Unit prices = quantity x unit_price\n",
    "items = items.assign(unit_prices = lambda x: x.unit_price * x.product_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge order + items + product, assign new columns for price * qty (for each price)\n",
    "orders_merg = (orders\n",
    ".merge(items, \"left\", on=\"order_id\")\n",
    ".merge(products, \"left\", on=\"sku\")\n",
    ".assign(unit_prices = lambda x: x.unit_price * x.product_quantity,\n",
    "        prices = lambda x: x.price * x.product_quantity,\n",
    "        promo_prices_est = lambda x: x.promo_price_est * x.product_quantity)\n",
    ".loc[:,[\"order_id\", \"state\" ,\"total_paid\", \"product_quantity\", \"unit_price\", \"unit_prices\", \"price\", \"prices\", \"promo_price_est\", \"promo_prices_est\",\"discount_est\", \"sku\", \"name\"]]\n",
    ".sort_values([\"order_id\"], ascending=False)\n",
    "#.tail(50)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tables, group by order and aggregat to calculate the different prices (total_paid, unit_price, price, promo_price) per order. -> derive discounts, voucher and shipping costs from that\n",
    "orders_agg = (orders\n",
    ".merge(items, \"left\", on=\"order_id\")\n",
    ".merge(products, \"left\", on=\"sku\")\n",
    ".assign(unit_prices = lambda x: x.unit_price * x.product_quantity,\n",
    "        prices = lambda x: x.price * x.product_quantity,\n",
    "        promo_prices_est = lambda x: x.promo_price_est * x.product_quantity)\n",
    ".groupby(\"order_id\")\n",
    ".agg({\"total_paid\":\"mean\", \"unit_prices\": \"sum\", \"prices\":\"sum\", \"promo_prices_est\":\"sum\", \"product_quantity\" :\"sum\"})\n",
    ".rename(columns={\"unit_prices\":\"sum_prices_as_shopped\",\"prices\":\"sum_prices_as_listed\", \"promo_prices_est\":\"sum_dicount_prices_as_listed\",\"product_quantity\":\"qty\"})\n",
    ".reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute discount\n",
    "orders_agg[\"discount_perc\"] = (100 - (orders_agg.sum_prices_as_shopped / orders_agg.sum_prices_as_listed * 100)).round(1)\n",
    "orders_agg[\"discount\"] = (orders_agg.sum_prices_as_listed - orders_agg.sum_prices_as_shopped)\n",
    "# overall it makes sense, but in some cases its negative. maybe prices changed over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute discount from the estimated discount (original promo_price)\n",
    "orders_agg[\"discount_est_perc\"] = (100 - (orders_agg.sum_dicount_prices_as_listed / orders_agg.sum_prices_as_listed * 100)).round(1) \n",
    "orders_agg[\"discount_est\"] = (orders_agg.sum_dicount_prices_as_listed - orders_agg.sum_prices_as_shopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute freight costs: freight = total_paid - summed_item_prices_per_order\n",
    "orders_agg[\"freight\"] = (orders_agg[\"total_paid\"] - orders_agg[\"sum_prices_as_shopped\"]).round(2)\n",
    "# overall reasonalbe, but some weird outliers - negative and high positive costs. \n",
    "# negative values could be vouchers/discounts (less paid then items costs) but what about the high positive values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add date to orders_agg\n",
    "orders_agg = orders_agg.merge(orders[[\"order_id\",\"date\"]], how=\"left\", on=\"order_id\")\n",
    "\n",
    "orders_agg.isna().any() # good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship of discounts and prices:\n",
    "temp_merg = products.merge(items, \"right\", on=\"sku\")\n",
    "temp_merg_agg = temp_merg.groupby(\"sku\").agg({\"price\": [\"min\",\"max\",\"mean\"], \"unit_price\": [\"min\",\"max\",\"mean\"]}) \n",
    "temp_merg_agg.sample(20)  # product prices (ffrom products) represent \"fixed\" prices. Information about changing product prices is missing. \n",
    "(temp_merg_agg[(\"unit_price\",\"mean\")] != temp_merg_agg[(\"unit_price\",\"max\")]).value_counts()  # discount changes with different unit_prices over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add discount per item\n",
    "temp_merg[\"unit_discount\"] = temp_merg.price - temp_merg.unit_price\n",
    "temp_merg[\"unit_discount_perc\"] = (temp_merg[\"unit_discount\"] / temp_merg.price *100).round(2)\n",
    "items = items.merge(temp_merg[[\"unit_discount\", \"unit_discount_perc\", \"id\"]],\"left\", \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate weird freight and discount numbers - failure of prior data cleaning or faulty data or systemic behavior in data?\n",
    "orders_agg.freight.describe() \n",
    "orders_agg.nlargest(20, \"freight\") # the first 4 lines seem faulty - unit_price is unreasonanly low while the other prices relate to each other. drop those.\n",
    "orders_agg.nsmallest(20, \"freight\") # the negative values might be vouchers - but there is no way to differiante between voucher and freight costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the other prices\n",
    "orders_agg[\"sum_prices_as_shopped\"].plot(kind=\"box\");\n",
    "#plt.show() # there are many outliers, but quiet reasonable\n",
    "orders_agg[\"sum_prices_as_shopped\"].describe()\n",
    "orders_agg.nlargest(20, \"sum_prices_as_shopped\") # there are high prices but they are reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_agg[\"discount_perc\"].describe()\n",
    "orders_agg[\"discount_perc\"].plot(kind=\"box\");\n",
    "#plt.show()\n",
    "orders_agg.nsmallest(20, \"discount_perc\") # there are high prices but they are reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some discounts seem not reliable\n",
    "items.loc[items.unit_discount_perc < -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detail look at chosen weird numbers\n",
    "weird_ids = [297148,293308,512894,508825,1233154,379925,388586,347233]\n",
    "orders_merg.loc[orders_merg[\"order_id\"].isin(weird_ids)]# .sort_values(\"order_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove weird rows in all relevant tables\n",
    "items = items[~items.order_id.isin(weird_ids)]\n",
    "orders = orders[~orders.order_id.isin(weird_ids)]\n",
    "orders_agg = orders_agg[~orders_agg.order_id.isin(weird_ids)]\n",
    "orders_merg = orders_merg[~orders_merg.order_id.isin(weird_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mp\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import addcopyfighandler\n",
    "from collections import Counter\n",
    "import os\n",
    "import pandasai as pai\n",
    "from pandasai.llm import OpenAI\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Products table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products[\"category\"] = \"\"\n",
    "products_all = products.copy()\n",
    "products = products.merge(brands, \"left\", left_on=products.sku.str[0:3], right_on=\"short\").rename(columns={\"long\":\"brand\"}).drop(columns=[\"short\",\"short\"])\n",
    "products = products.loc[products.sku.isin(products.merge(items, \"inner\", \"sku\")[\"sku\"].drop_duplicates())]   # CAUTION - remove unneeded products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the pattern of the product \"type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.loc[products.category == \"\",[\"name\",\"desc\",\"price\",\"type\"]].value_counts(\"type\").nlargest(20)\n",
    "products.loc[products.type.isna(),[\"name\",\"desc\",\"price\",\"type\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to 1. manually check common category of each type and 2. count the most frequent word in he names of those products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_info(x):\n",
    "    print(products.loc[products.type == x,[\"name\",\"desc\",\"price\",\"type\",\"sku\",\"brand\"]])\n",
    "\n",
    "    print(pd.DataFrame(Counter(\" \".join(products.loc[products.type == x,\"name\"]\n",
    "                            .replace(r'[^\\w\\s]|_', '', regex=True)\n",
    "                            .replace(r' +', ' ',regex=True))\n",
    "                            .split())\n",
    "                .most_common(15))\n",
    "    )\n",
    "    print(products.loc[products.type == x,\"type\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: use this function to manually check each \"type\" in the order of its size and assign a meaninfgul name to it.\n",
    "Step 2: Decide for categories and reassign all types into those categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign product categories\n",
    "products.loc[products.type == \"11865403\",\"category\"] = \"Accessory\"          # casing\n",
    "products.loc[products.type == \"12175397\",\"category\"] = \"Network/Memory\"     # \"NAS Server\"\n",
    "products.loc[products.type == \"1298\",\"category\"] = \"\"                       # Mix :/\n",
    "products.loc[products.type == \"11935397\",\"category\"] = \"Network/Memory\"     # \"USB Hard Drive\"\n",
    "products.loc[products.type == \"11905404\",\"category\"] = \"\"                   # Mix :/\n",
    "products.loc[products.type == \"1282\",\"category\"] = \"Computer/Laptop\"        # Mac\n",
    "products.loc[products.type == \"12635403\",\"category\"] = \"Accessory\"          # Caseing    \n",
    "products.loc[products.type == \"13835403\",\"category\"] = \"Accessory\"          # Casing\n",
    "products.loc[products.type == \"5,74E+15\",\"category\"] = \"Accessory\"          # iMac\n",
    "products.loc[products.type == \"1364\",\"category\"] = \"Network/Memory\"         # Memory\n",
    "products.loc[products.type == \"12585395\",\"category\"] = \"Electronic Accessory\"# USB Adapter\n",
    "products.loc[products.type == \"1296\",\"category\"] = \"Monitor\"                # Monitor\n",
    "products.loc[products.type == \"1325\",\"category\"] = \"Electronic Accessory\"   # Cable\n",
    "products.loc[products.type == \"5384\",\"category\"] = \"Multimedia\"             # Headphones\n",
    "products.loc[products.type == \"1433\",\"category\"] = \"Network/Memory\"         # SSD\n",
    "products.loc[products.type == \"12215397\",\"category\"] = \"Network/Memory\"     # SSD\n",
    "products.loc[products.type == \"5398\",\"category\"] = \"Multimedia\"             # Speaker\n",
    "products.loc[products.type == \"1,02E+12\",\"category\"] = \"Computer/Laptop\"    # MacBook Pro\n",
    "products.loc[products.type == \"57445397\",\"category\"] = \"Network/Memory\"     # Memory\n",
    "products.loc[products.type == \"1,44E+11\",\"category\"] = \"Service/Repair\"     # Service/Repair\n",
    "products.loc[products.type == \"1334\",\"category\"] = \"Network/Memory\"         # Network/Memory\n",
    "products.loc[products.type == \"2158\",\"category\"] = \"\"        # MacBook Pro\n",
    "products.loc[products.type == \"2449\",\"category\"] = \"Accessory\"              # Apple watch Accessories\n",
    "products.loc[products.type == \"12655397\",\"category\"] = \"Network/Memory\"     # NAS Hard Drive\n",
    "products.loc[products.type == \"1229\",\"category\"] = \"Electronic Accessory\"   # Apple Pen Pointer\n",
    "products.loc[products.type == \"12995397\",\"category\"] = \"Network/Memory\"     # \"Hard Drive ao Accessories\" \n",
    "products.loc[products.type == \"1515\",\"category\"] = \"Electronic Accessory\"   # Battery\n",
    "products.loc[products.type == \"13615399\",\"category\"] = \"Electronic Accessory\"# Charger \n",
    "products.loc[products.type == \"13555403\",\"category\"] = \"Accessory\"          #Screen Protection\n",
    "products.loc[products.type == \"1405\",\"category\"] = \"Tablet\"                 # Graphic Tablet \n",
    "products.loc[products.type == \"1230\",\"category\"] = \"Electronic Accessory\"   # Lightning Cable\n",
    "products.loc[products.type == \"118692158\",\"category\"] = \"Computer/Laptop\"   # iMac\n",
    "products.loc[products.type == \"1216\",\"category\"] = \"Accessory\"              # Apple Stand Mounts\n",
    "products.loc[products.type == \"24885185\",\"category\"] = \"Wearable\"           # Apple Watch\n",
    "products.loc[products.type == \"24895185\",\"category\"] = \"Wearable\"           # Apple Watch\n",
    "products.loc[products.type == \"21485407\",\"category\"] = \"Service/Repair\"     # iPhone Repair\n",
    "products.loc[products.type == \"1392\",\"category\"] = \"Other\"                  # backpacks\n",
    "products.loc[products.type == \"11821715\",\"category\"] = \"Multimedia\"         # iPod\n",
    "products.loc[products.type == \"8696\",\"category\"] = \"Accessory\"              # Apple Stand Mounts\n",
    "products.loc[products.type == \"9094\",\"category\"] = \"Camera/Drone\"           # Camera\n",
    "products.loc[products.type == \"13835403\",\"category\"] = \"Accessory\"          # Casing\n",
    "products.loc[products.type.isin([\"85641716\",\"24811716\",\"24821716\",\"113291716\",\n",
    "                                 \"113281716\",\"113271716\",\"21561716\", \"85651716\",\n",
    "                                 \"51601716\"]),\"category\"] = \"Smartphone\"    # iPhones\n",
    "products.loc[products.type == \"1231\",\"category\"] = \"Service/Repair\"         # Apple Protection/ Warrenty\n",
    "products.loc[products.type == \"1387\",\"category\"] = \"Electronic Accessory\"   # Mouse\n",
    "products.loc[products.type == \"12755395\",\"category\"] = \"Network/Memory\"     # HDD and Kits\n",
    "products.loc[products.type == \"13855401\",\"category\"] = \"Electronic Accessory\"# Keyboards\n",
    "products.loc[products.type == \"\",\"category\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "like 80 % has been assigned. for now, thats okay. \n",
    "go on and check if other categories fall into mind or need to be found for top sales products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.loc[((products.category == \"\") | (products.category == \"Mix\")) & (products.name.str.contains('|'.join([\"case\"]), case=False)), \"category\"] = \"Accessory\" # casing\n",
    "products.loc[((products.category == \"\") | (products.category == \"Mix\")) & (products.name.str.contains('|'.join([\"charger\"]), case=False)), \"category\"] = \"Electronic Accessory\" # Charger\n",
    "products.loc[((products.category == \"\") | (products.category == \"Mix\")) & (products.name.str.contains('|'.join([\"iMAC\"]), case=False)) & (products.price > 500), \"category\"] = \"Computer/Laptop\" # iMac\n",
    "products.loc[((products.category == \"\") | (products.category == \"Mix\")) & (products.name.str.contains('|'.join([\"ipad\"]), case=False)) & (products.brand == \"Apple\") & (products.price > 200), \"category\"] = \"Tablet\" # iPad\n",
    "products.loc[((products.category == \"\") | (products.category == \"Mix\")) & (products.name.str.contains('|'.join([\"Mac\"]), case=False)) & (products.price > 400),\"category\"] = \"Computer/Laptop\" #Mac\n",
    "products.loc[((products.category == \"\") | (products.category == \"Mix\")) & (products.name.str.contains('|'.join([\"drone\"]), case=False)), \"category\"] = \"Camera/Drone\" # Drone\n",
    "products.loc[products.name.str.contains('|'.join([\"used\",\"like new\", \"refurbish\",\"second hand\",\"nearly new\", \"secondhand\"]), case=False), \"category\"] = \"Second Hand\"\n",
    "\n",
    "products.loc[(products.category == \"\") | (products.category == \"Mix\")].nlargest(30,\"price\")\n",
    "products.loc[((products.category == \"\") | (products.category == \"Mix\")) & (products.name.str.contains(''.join([\"nas\"]), case=False))]\n",
    "\n",
    "(pd.DataFrame(Counter(\" \".join(products.loc[(products.category == \"\") | (products.category == \"Mix\"),\"name\"]\n",
    "                            .replace(r'[^\\w\\s]|_', '', regex=True)\n",
    "                            .replace(r' +', ' ',regex=True))\n",
    "                            .split())\n",
    "                .most_common(30))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.category.value_counts()\n",
    "products.sample(30)\n",
    "products.loc[products.sku == \"APP1970\"]\n",
    "\n",
    "cat_info(\"113291716\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category for Second Hand Material\n",
    "Category for Rest <- about 20%. That is not satisfactory, but as this process is really time-consuming, its good for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign \"miscellaneous\" to the rest (~1000 products) - further categorize those later, if there is time\n",
    "products.loc[products.category == \"\", \"category\"] = \"Miscellaneous\"\n",
    "\n",
    "# Second Hand\n",
    "products.loc[products.name.str.contains('|'.join([\"used\",\"like new\", \"refurbish\",\"second hand\",\"nearly new\", \"secondhand\"]), case=False), \"category\"] = \"Second Hand\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category approach using PandasAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_ai = products.copy().drop(columns=[\"type\", \"in_stock\", \"discount_est\", \"promo_price_est\", \"sku\"])\n",
    "llm = OpenAI(api_token=\"API KEY HERE\",\n",
    "             model_name = 'gpt-3.5-turbo')\n",
    "\n",
    "orders_smart = pai.SmartDataframe(products_ai, config={\"llm\": llm}, name=\"products\", description=\"List of offered products\")\n",
    "Agent = pai.Agent(products_ai)\n",
    "\n",
    "orders_smart.chat(\"what are the most expensive products?\")\n",
    "Agent.chat(\"what are the most expensive products?\")\n",
    "Agent.clarification_questions(\"what are the most expensive products?\")\n",
    "Agent.explain()\n",
    "\n",
    "#Agent.chat(\"\"\"categorize all products within a new column 'category_ai', based on the keywords within  \"name\" and \"des\" columns. Use the following categories (examples in parantheses) and adapt and/or expand if necessary. \n",
    "#              Categories: Computer/Laptop (MacBook, iMac), Tablet (iPad, graphic Tablet), Smartphone (iPhone), Wearable (Apple Watch), Network/Memory (external / USB Hard Drive, NAS Server, SSD),\n",
    "#              Monitor, Electronic Asseccory (Cables, Battery, Charger, Lighning, Pen, USB Adapter, Mouse, Keyboard), Accessory (Cases, Stands, Mounts, Screen Protection), Multimedia (Headphones, Speaker, iPod),\n",
    "#              Service (Repair, Parts, Protection Plan), Camera/Drone.\n",
    "#           \"\"\")\n",
    "\n",
    "#Agent.chat(\"\"\"Based on the \"name\" and \"description\" columns, categorize each product into the correct category and create a new column 'category_ai' for the result. \n",
    "#The categories include Computer/Laptop, Tablet, Smartphone, Wearable, Network/Memory, Monitor, Electronic Accessory, Accessory, Multimedia, Service, and Camera/Drone. \n",
    "#Please adapt or expand the categories as necessary based on product keywords.\"\"\")\n",
    "\n",
    "#Agent.chat(\"\"\"Categorize all products into categories within a new column 'category_ai'. Base your assignment on the product name. The categories include Computer/Laptop, Tablet, Smartphone, Wearable, Network/Memory, Monitor, Electronic Accessory, Accessory, Multimedia, Service, and Camera/Drone.\"\"\")\n",
    "\n",
    "#Agent.chat(\"Do not use 'other', but one of the existing category names from column 'category'. based on the product descript in 'name' and des'\")\n",
    "\n",
    "\n",
    "orders_smart.chat(\"\"\"Given the following categories, write a script to categorize these products, using information\n",
    "in the name and desc columns. Save the result in a new column \"category_ai.\n",
    "Categories: Computer/Laptop, Tablet, Smartphone, Wearable, Network/Memory, Monitor, Electronic Accessory, Accessory, Multimedia, Service, and Camera/Drone\n",
    "#\n",
    "# - Computer/Laptop: 'Lenovo ThinkPad X1 Carbon', 'Apple MacBook Pro', 'iMac'\n",
    "# - Tablet: 'Apple iPad Air', 'Samsung Galaxy Tab S7'\n",
    "# - Smartphone: 'Samsung Galaxy S21', 'Apple iPhone 12'\n",
    "# - Wearable: 'Apple Watch Series 6', 'Fitbit Versa 3'\n",
    "# - Network/Memory: 'Synology DS218j NAS', 'Samsung EVO 1TB SSD'\n",
    "# - Monitor: 'Dell Ultrasharp 24 Monitor', 'ASUS ProArt Display PA278QV'\n",
    "# - Electronic Accessory: 'Anker PowerCore Portable Charger', 'Belkin Boost Up Wireless Charging Pad'\n",
    "# - Accessory: 'OtterBox Defender Series Phone Case', 'JETech Screen Protector'\n",
    "# - Multimedia: 'Sony WH-1000XM4 Wireless Headphones', 'Bose SoundLink Mini Bluetooth Speaker'\n",
    "# - Service/Repair: 'AppleCare Protection Plan', 'Samsung Premium Care'\n",
    "# - Camera/Drone: 'Canon EOS R5 Mirrorless Camera', 'DJI Mavic Air 2 Drone'\n",
    "\n",
    "# Consider the main function of the product as described by its name for categorization.\n",
    "\"\"\")\n",
    "print(orders_smart.last_code_generated)\n",
    "products_ai.sample(30)\n",
    "products.nlargest(5, \"price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.info()\n",
    "items.info()\n",
    "products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save to csv\n",
    "items.to_csv(folder+'items_clean.csv', index=False)\n",
    "products.to_csv(folder+'products_clean.csv', index=False)\n",
    "orders.to_csv(folder+'orders_clean.csv', index=False)\n",
    "brands.to_csv(folder+'brands_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
